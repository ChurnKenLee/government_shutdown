{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#OPM-Employment-Data-(Non-DOD)\" data-toc-modified-id=\"OPM-Employment-Data-(Non-DOD)-1\">OPM Employment Data (Non-DOD)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-Constants\" data-toc-modified-id=\"Imports-and-Constants-1.1\">Imports and Constants</a></span></li><li><span><a href=\"#Functions-for-Easier-Loading\" data-toc-modified-id=\"Functions-for-Easier-Loading-1.2\">Functions for Easier Loading</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dynamic-Data\" data-toc-modified-id=\"Dynamic-Data-1.2.1\">Dynamic Data</a></span></li><li><span><a href=\"#Status-Data\" data-toc-modified-id=\"Status-Data-1.2.2\">Status Data</a></span></li></ul></li><li><span><a href=\"#Analysis\" data-toc-modified-id=\"Analysis-1.3\">Analysis</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPM Employment Data (Non-DOD)\n",
    "<hr style='height:3px'>\n",
    "    This notebook is meant to assist in analyzing the OPM non-DOD data and has helper functions to make your life easier. The data is Buzzfeed's OPM data, hosted <a href=\"https://archive.org/details/opm-federal-employment-data/docs/2015-02-11-opm-foia-response/\">here</a> on the Internet Archive. To download, <a href=\"https://archive.org/compress/opm-federal-employment-data\" target=\"_blank\">click this link</a>. It's about 34 GB. It will be structured in the same way as the data I am using here (made explicit at the bottom of this cell).\n",
    "\n",
    "The data outside the 1973-09 to 2014-06 range is horribly arranged. I've forgone making the load functions handle that data. If you need to load that data, feel free to contact me and I'll make and send over a script that can handle them. I don't think they even have the dynamic files after that end date, just the status files.\n",
    "\n",
    "\n",
    "This is using:<br>\n",
    "Python 3.8.3 or higher<br>\n",
    "Pandas 1.0.5 or higher\n",
    "\n",
    "\n",
    "The folder containing the data is structured as:\n",
    "    <ul>\n",
    "        <li>.\\opm-federal-employment-data</li>\n",
    "        <ul>\n",
    "            <li>data</li>\n",
    "            <ul>\n",
    "                <li>1973-09-to-2014-06</li>\n",
    "                <ul>\n",
    "                    <li>dod</li>\n",
    "                    <ul>\n",
    "                        <li>Irrelevant for us</li>\n",
    "                    </ul>\n",
    "                    <li>non-dod</li>\n",
    "                    <ul>\n",
    "                        <li>dynamic</li>\n",
    "                        <ul>\n",
    "                            <li>\\*.NONDOD.FO05M3.TXT</li>\n",
    "                        </ul>\n",
    "                        <li>status</li>\n",
    "                        <ul>\n",
    "                            <li>Status_Non_DoD_\\*.txt</li>\n",
    "                        </ul>\n",
    "                    </ul>\n",
    "                    <li>SCTFILE.TXT</li>\n",
    "                </ul>\n",
    "                <li>2014-09-to-2016-09</li>\n",
    "                <ul>\n",
    "                    <li>Irrelevant for us</li>\n",
    "                </ul>\n",
    "                <li>2016-12-to-2017-03</li>\n",
    "                <ul>\n",
    "                    <li>Irrelevant for us</li>\n",
    "                </ul>\n",
    "            </ul>\n",
    "            <li>docs</li>\n",
    "            <ul>\n",
    "                <li>Irrelevant for us</li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T02:25:08.804441Z",
     "start_time": "2021-01-18T02:25:08.786959Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "\n",
    "\n",
    "dynamic_dir = os.path.join(\".\", \"opm-federal-employment-data\",\n",
    "                           \"data\", \"1973-09-to-2014-06\", \"non-dod\", \"dynamic\")\n",
    "\n",
    "status_dir = os.path.join(\".\", \"opm-federal-employment-data\",\n",
    "                          \"data\", \"1973-09-to-2014-06\", \"non-dod\", \"status\")\n",
    "\n",
    "fwf_columns = OrderedDict([\n",
    "    ('Pseudo ID', (0, 9)),\n",
    "    ('Name', (9, 32)),\n",
    "    ('File Date', (32, 40)),\n",
    "    ('SubAgency', (40, 44)),\n",
    "    ('Duty Station', (44, 53)),\n",
    "    ('Age Range', (53, 59)),\n",
    "    ('Education Level', (59, 61)),\n",
    "    ('Pay Plan', (61, 63)),\n",
    "    ('Grade', (63, 65)),\n",
    "    ('LOS Level', (65, 71)),\n",
    "    ('Occupation', (71, 75)),\n",
    "    ('PATCO', (75, 76)),\n",
    "    ('Adjusted Basic Pay', (76, 82)),\n",
    "    ('Supervisory Status', (82, 83)),\n",
    "    ('TOA', (83, 85)),\n",
    "    ('Work Schedule', (85, 86)),\n",
    "    ('NSFTP Indicator', (86, 87))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Easier Loading\n",
    "<hr>\n",
    "The goal here is to abstract away the bad naming scheme of the files. The data is partitioned by qaurter. You can run the functions without arguments to load just the first file in each category (status vs. dynamic). I recommend this so you can get your bearings with the data without much wait time.\n",
    "\n",
    "Heads up that, for me, 16GB of RAM wasn't enough for ~1980-2005. If you need code to run on data that's larger than your RAM, using a cloud compute solution can work if you use cURL in the terminal with the link https ://archive .org/compress/opm-federal-employment-data (I put spaces in the link so you don't accidentally click on it and start downloading the files again)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Data\n",
    "The dynamic data is a quarterly report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T02:30:23.249807Z",
     "start_time": "2021-01-18T02:30:23.236141Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dynamic(start_date: str = \"1982-03\", end_date: str = \"1982-04\") -> pd.DataFrame:\n",
    "    \"\"\"Loads the dynamic file for the given date range. Keep in mind, the data can get sizeable really quickly.\n",
    "    Date is passed in a YYYY-MM format in the defaults, but this should handle several date formats. The reports\n",
    "    are quarterly, so the months should be December, March, June, or September. The start and end date defaults\n",
    "    were chosen because they are the dates with available data.\"\"\"\n",
    "    if start_date > end_date:\n",
    "        raise Exception(\n",
    "            \"Remember to have an end date *after* the start date. No file loading was done.\"\n",
    "        )\n",
    "        return\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    df = pd.DataFrame()\n",
    "    files_to_load = []  # files are not sorted in the directory, so the data would be messier\n",
    "    for file in os.listdir(dynamic_dir):\n",
    "        file_date = pd.to_datetime(file[:7])\n",
    "        if start_date <= file_date <= end_date:\n",
    "            files_to_load.append(file)\n",
    "    files_to_load = sorted(files_to_load, key=lambda x: pd.to_datetime(x[:7]))\n",
    "    for file in files_to_load:\n",
    "        df = df.append(pd.read_fwf(os.path.join(dynamic_dir, file),\n",
    "                                   colspecs=list(fwf_columns.values()),\n",
    "                                   header=None,\n",
    "                                   names=list(fwf_columns.keys())))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status Data\n",
    "The status data is a quarterly report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T02:35:08.208428Z",
     "start_time": "2021-01-18T02:35:08.189776Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_status(start_date: str = \"1973-09\", end_date: str = \"1973-12\") -> pd.DataFrame:\n",
    "    \"\"\"Loads the status file for the given date range. Keep in mind, the data can get sizeable really quickly.\n",
    "    Date is passed in a YYYY-MM format in the defaults, but this should handle several date formats. The reports\n",
    "    are quarterly, so the months should be December, March, June, or September. The start and end date defaults\n",
    "    were chosen because they are the dates with available data.\"\"\"\n",
    "    if start_date > end_date:\n",
    "        raise Exception(\n",
    "            \"Remember to have an end date *after* the start date. No file loading was done.\"\n",
    "        )\n",
    "        return\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    df = pd.DataFrame()\n",
    "    files_to_load = []  # files are not sorted in the directory, so the data would be messier\n",
    "    for file in os.listdir(status_dir):\n",
    "        file_date = pd.to_datetime(\"-\".join(file[-11:-4].split(\"_\")))\n",
    "        if start_date <= file_date <= end_date:\n",
    "            files_to_load.append(file)\n",
    "    files_to_load = sorted(files_to_load, key=lambda x: pd.to_datetime(\n",
    "        \"-\".join(file[-11:-4].split(\"_\"))))\n",
    "    for file in files_to_load:\n",
    "        df = df.append(pd.read_fwf(os.path.join(status_dir, file),\n",
    "                                   colspecs=list(fwf_columns.values()),\n",
    "                                   header=None,\n",
    "                                   names=list(fwf_columns.keys())))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "<hr style=\"height:3px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
