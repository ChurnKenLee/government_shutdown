{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_rename_dict = {\n",
    "    'OPM SERIES NUMBER (December 2018)': 'opm_occ_code',\n",
    "    'OPM SERIES TITLE\\xa0\\n(December 2018)': 'opm_occ_title',\n",
    "    '2018 \\nSOC CODE': '2018_soc_code',\n",
    "    '2014-2018 EEO TABULATION (CENSUS) CODE': 'census_occ_code',\n",
    "    '2014-2018 EEO TABULATION (CENSUS) OCCUPATION TITLE': 'census_occ_title'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OPM occupation code to SOC code crosswalk\n",
    "opm_occ_df = pd.read_excel('../raw_data/MD715-Census Occupation Crosswalk 2022Feb23.xlsx', header = 2, dtype = 'str')\n",
    "opm_occ_df.rename(columns = occ_rename_dict, inplace = True)\n",
    "opm_occ_df = opm_occ_df[list(occ_rename_dict.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing #, which indicates deviations from documentation of the 2014-2018 EEO Tabulation\n",
    "for col in opm_occ_df.columns:\n",
    "    opm_occ_df[col] = opm_occ_df[col].str.replace('#', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutystation_rename_dict = {\n",
    "    'Code': 'duty_station_code',\n",
    "    'CBSA': 'cbsa',\n",
    "    'CSA': 'csa',\n",
    "    'City': 'city',\n",
    "    'County': 'county',\n",
    "    'State': 'state',\n",
    "    'Country': 'country'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load duty station to county crosswalk file\n",
    "opm_dutystation_df = pd.read_excel('../raw_data/opm_dutystation.xlsx', dtype = 'str')\n",
    "opm_dutystation_df.rename(columns = dutystation_rename_dict, inplace = True)\n",
    "opm_dutystation_df = opm_dutystation_df[list(dutystation_rename_dict.values())]\n",
    "\n",
    "# Pad duty station code to 9 characters with 0s on the left\n",
    "opm_dutystation_df['duty_station_code'] = opm_dutystation_df['duty_station_code'].str.pad(9, side = 'left', fillchar = '0')\n",
    "\n",
    "# Remove duty stations not in a county\n",
    "opm_dutystation_df = opm_dutystation_df[~opm_dutystation_df['county'].isna()]\n",
    "opm_dutystation_df['msa_code'] = pd.Series(dtype = 'str') # Add column for MSA code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load QCEW county-MSA crosswalk\n",
    "qcew_df = pd.read_excel('../raw_data/qcew-county-msa-csa-crosswalk-xlsx.xlsx')\n",
    "#qcew_df = qcew_df[~qcew_df['MSA Code'].isna()]\n",
    "qcew_df.loc[qcew_df['MSA Code'].isna(), 'MSA Code'] = 'matched'\n",
    "\n",
    "# Split conty title into county and state columns, capitalized to merge with OPM dutystation code file\n",
    "qcew_df['county'] = qcew_df['County Title'].str.split(', ').str[0]\n",
    "qcew_df['state'] = qcew_df['County Title'].str.split(', ').str[1]\n",
    "\n",
    "qcew_df['state'] = qcew_df['state'].str.upper()\n",
    "qcew_df.loc[qcew_df['state'].isna(), 'state'] = 'DISTRICT OF COLUMBIA' # DC has blank state\n",
    "qcew_df.loc[qcew_df['state'] == 'AK', 'state'] = 'ALASKA' # One entry has AK instead of Alaska\n",
    "\n",
    "qcew_df['county'] = qcew_df['county'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of states that are in both QCEW and OPM (50 states + DC)\n",
    "qcew_state_list = list(qcew_df['state'].unique())\n",
    "opm_dutystation_state_list = list(opm_dutystation_df['state'].unique())\n",
    "state_list = list(set(qcew_state_list) & set(opm_dutystation_state_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over states and counties to add MSA code to OPM dutystation df\n",
    "for state_name in state_list:\n",
    "    county_list = list(opm_dutystation_df['county'][opm_dutystation_df['state'] == state_name].unique())\n",
    "    for county_name in county_list:\n",
    "\n",
    "        qcew_county_name = county_name.replace('SAINT ', 'ST. ')\n",
    "        qcew_county_name = qcew_county_name.replace('DE KALB', 'DEKALB')\n",
    "        qcew_county_name = qcew_county_name.replace('DU PAGE', 'DUPAGE')\n",
    "        qcew_county_name = qcew_county_name.replace('LA PORTE', 'LAPORTE')\n",
    "        qcew_county_name = qcew_county_name.replace('DONA ANA', 'DOÃ‘A ANA')\n",
    "        qcew_county_name = qcew_county_name.replace('LA MOURE', 'LAMOURE')\n",
    "        qcew_county_name = qcew_county_name.replace('SPAULDING', 'SPALDING') # Typo in OPM county name\n",
    "        qcew_county_name = qcew_county_name.replace('O BRIEN', 'OBRIEN')\n",
    "        qcew_county_name = qcew_county_name.replace('STE GENEVIEVE', 'STE. GENEVIEVE')\n",
    "        # La Salle has a space in Texas, but not in other states\n",
    "        if state_name != 'TEXAS':\n",
    "            qcew_county_name = qcew_county_name.replace('LA SALLE', 'LASALLE')\n",
    "        # De Soto has a space in Louisiana, but not in other states\n",
    "        if state_name != 'LOUISIANA':\n",
    "            qcew_county_name = qcew_county_name.replace('DE SOTO', 'DESOTO')\n",
    "\n",
    "        try:\n",
    "            msa_code = qcew_df[(qcew_df['state'] == state_name) & (qcew_df['county'].str.contains(qcew_county_name))]['MSA Code'].iloc[0]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        opm_dutystation_df.loc[(opm_dutystation_df['state'] == state_name) & (opm_dutystation_df['county'] == county_name), 'msa_code'] = msa_code # Assign MSA code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All counties matched, with counties outside MSAs assigned an MSA code of 'matched'\n",
    "sum(opm_dutystation_df['msa_code'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dicts of paths of binaries\n",
    "with open('../code_output/opm_nondod_status_pre2014_feather_path_dict.json', 'r') as infile:\n",
    "    opm_nondod_status_feather_path_dict = json.load(infile)\n",
    "\n",
    "with open('../code_output/opm_dod_status_pre2014_feather_path_dict.json', 'r') as infile:\n",
    "    opm_dod_status_feather_path_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opm_collapsed_feather_path_dict = {}\n",
    "binary_path = Path('../cleaned_binaries/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing year 1990.\n",
      "Collapsing year 1991.\n",
      "Collapsing year 1992.\n",
      "Collapsing year 1993.\n",
      "Collapsing year 1994.\n",
      "Collapsing year 1995.\n",
      "Collapsing year 1996.\n",
      "Collapsing year 1997.\n",
      "Collapsing year 1998.\n",
      "Collapsing year 1999.\n",
      "Collapsing year 2000.\n",
      "Collapsing year 2001.\n",
      "Collapsing year 2002.\n",
      "Collapsing year 2003.\n",
      "Collapsing year 2004.\n",
      "Collapsing year 2005.\n",
      "Collapsing year 2006.\n",
      "Collapsing year 2007.\n",
      "Collapsing year 2008.\n",
      "Collapsing year 2009.\n",
      "Collapsing year 2010.\n",
      "Collapsing year 2011.\n",
      "Collapsing year 2012.\n",
      "Collapsing year 2013.\n",
      "Collapsing year 2014.\n"
     ]
    }
   ],
   "source": [
    "for year, qtr_dict in opm_nondod_status_feather_path_dict.items():\n",
    "    year_df = pd.DataFrame()\n",
    "\n",
    "    if int(year) < 1990:\n",
    "        continue\n",
    "    \n",
    "    print(f'Collapsing year {year}.')\n",
    "\n",
    "    for qtr, file_path in qtr_dict.items():\n",
    "        df = pd.read_feather(Path(file_path))\n",
    "        year_df = pd.concat([year_df, df])\n",
    "\n",
    "    year_df = year_df[['Pseudo-ID', 'Employee Name', 'Duty Station', 'Occupation', 'Adjusted Basic Pay']] # Keep only variables we want\n",
    "    \n",
    "    # Add CBSA and SOC codes\n",
    "    merged_df = year_df.merge(opm_occ_df, how = 'inner', left_on = ['Occupation'], right_on = ['opm_occ_code'])\n",
    "    merged_df = merged_df.merge(opm_dutystation_df, how = 'inner', left_on = ['Duty Station'], right_on = ['duty_station_code'])\n",
    "\n",
    "    # Keep only 1 observation per worker in a given year\n",
    "    merged_df = merged_df[merged_df['msa_code'] != 'matched'] # Drop people who do not have an MSA code\n",
    "    merged_df.drop_duplicates(subset = ['Pseudo-ID'])\n",
    "\n",
    "    # Collapse by SOC code and CBSA\n",
    "    collapsed_df = merged_df.groupby(by = ['2018_soc_code', 'msa_code']).agg({\n",
    "        'Pseudo-ID': 'count',\n",
    "        'Adjusted Basic Pay': 'mean',\n",
    "        'opm_occ_code': 'first',\n",
    "        'opm_occ_title': 'first',\n",
    "        'census_occ_code': 'first',\n",
    "        'census_occ_title': 'first',\n",
    "        'county': 'first',\n",
    "        'state': 'first',\n",
    "    })\n",
    "\n",
    "    # Cleap up collapsed df and export\n",
    "    collapsed_df.reset_index(inplace = True)\n",
    "    collapsed_df.rename(columns = {'Pseudo-ID': 'opm_n_emp', 'Adjusted Basic Pay': 'mean_abp'}, inplace = True)\n",
    "    \n",
    "    target_path = Path(binary_path).joinpath(f'opm_collapsed_{year}.feather')\n",
    "    collapsed_df.to_feather(target_path)\n",
    "\n",
    "    opm_collapsed_feather_path_dict[year] = str(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionaries for paths of binaries\n",
    "with open('../code_output/opm_collapsed_pre2014_feather_path_dict.json', 'w') as outfile:\n",
    "    json.dump(opm_collapsed_feather_path_dict, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d17b7b52486b7ddd73814d01c6691018dc71175d95eb65a2b9cd66e1b85695ed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
