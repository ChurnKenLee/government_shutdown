{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_rename_dict = {\n",
    "    'OPM SERIES NUMBER (December 2018)': 'opm_occ_code',\n",
    "    'OPM SERIES TITLE\\xa0\\n(December 2018)': 'opm_occ_title',\n",
    "    '2018 \\nSOC CODE': '2018_soc_code',\n",
    "    '2014-2018 EEO TABULATION (CENSUS) CODE': 'census_occ_code',\n",
    "    '2014-2018 EEO TABULATION (CENSUS) OCCUPATION TITLE': 'census_occ_title'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OPM occupation code to SOC code crosswalk\n",
    "opm_occ_df = pd.read_excel('../raw_data/MD715-Census Occupation Crosswalk 2022Feb23.xlsx', header = 2, dtype = 'str')\n",
    "opm_occ_df.rename(columns = occ_rename_dict, inplace = True)\n",
    "opm_occ_df = opm_occ_df[list(occ_rename_dict.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing #, which indicates deviations from documentation of the 2014-2018 EEO Tabulation\n",
    "for col in opm_occ_df.columns:\n",
    "    opm_occ_df[col] = opm_occ_df[col].str.replace('#', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutystation_rename_dict = {\n",
    "    'Code': 'duty_station_code',\n",
    "    'CBSA': 'cbsa',\n",
    "    'CSA': 'csa',\n",
    "    'City': 'city',\n",
    "    'County': 'county',\n",
    "    'State': 'state',\n",
    "    'Country': 'country'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load duty station to CBSA crosswalk file\n",
    "opm_dutystation_df = pd.read_excel('../raw_data/opm_dutystation.xlsx', dtype = 'str')\n",
    "opm_dutystation_df.rename(columns = dutystation_rename_dict, inplace = True)\n",
    "opm_dutystation_df = opm_dutystation_df[list(dutystation_rename_dict.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad duty station code to 9 characters with 0s on the left\n",
    "opm_dutystation_df['duty_station_code'] = opm_dutystation_df['duty_station_code'].str.pad(9, side = 'left', fillchar = '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dicts of paths of binaries\n",
    "with open('../code_output/opm_nondod_status_pre2014_feather_path_dict.json', 'r') as infile:\n",
    "    opm_nondod_status_feather_path_dict = json.load(infile)\n",
    "\n",
    "with open('../code_output/opm_dod_status_pre2014_feather_path_dict.json', 'r') as infile:\n",
    "    opm_dod_status_feather_path_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "opm_collapsed_feather_path_dict = {}\n",
    "binary_path = Path('../cleaned_binaries/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing year 1990.\n",
      "Collapsing year 1991.\n",
      "Collapsing year 1992.\n",
      "Collapsing year 1993.\n",
      "Collapsing year 1994.\n",
      "Collapsing year 1995.\n",
      "Collapsing year 1996.\n",
      "Collapsing year 1997.\n",
      "Collapsing year 1998.\n",
      "Collapsing year 1999.\n",
      "Collapsing year 2000.\n",
      "Collapsing year 2001.\n",
      "Collapsing year 2002.\n",
      "Collapsing year 2003.\n",
      "Collapsing year 2004.\n",
      "Collapsing year 2005.\n",
      "Collapsing year 2006.\n",
      "Collapsing year 2007.\n",
      "Collapsing year 2008.\n",
      "Collapsing year 2009.\n",
      "Collapsing year 2010.\n",
      "Collapsing year 2011.\n",
      "Collapsing year 2012.\n",
      "Collapsing year 2013.\n",
      "Collapsing year 2014.\n"
     ]
    }
   ],
   "source": [
    "for year, qtr_dict in opm_nondod_status_feather_path_dict.items():\n",
    "    year_df = pd.DataFrame()\n",
    "\n",
    "    if int(year) < 1990:\n",
    "        continue\n",
    "    \n",
    "    print(f'Collapsing year {year}.')\n",
    "\n",
    "    for qtr, file_path in qtr_dict.items():\n",
    "        df = pd.read_feather(Path(file_path))\n",
    "        year_df = pd.concat([year_df, df])\n",
    "\n",
    "    year_df = year_df[['Pseudo-ID', 'Employee Name', 'Duty Station', 'Occupation', 'Adjusted Basic Pay']] # Keep only variables we want\n",
    "    \n",
    "    # Add CBSA and SOC codes\n",
    "    merged_df = year_df.merge(opm_occ_df, how = 'inner', left_on = ['Occupation'], right_on = ['opm_occ_code'])\n",
    "    merged_df = merged_df.merge(opm_dutystation_df, how = 'inner', left_on = ['Duty Station'], right_on = ['duty_station_code'])\n",
    "\n",
    "    # Keep only 1 observation per worker in a given year\n",
    "    merged_df = merged_df.drop_duplicates(subset = ['Pseudo-ID'])\n",
    "\n",
    "    # Keep only workers that are within a CBSA\n",
    "    merged_df = merged_df[~merged_df['cbsa'].isna()]\n",
    "\n",
    "    # Collapse by SOC code and CBSA\n",
    "    collapsed_df = merged_df.groupby(by = ['2018_soc_code', 'cbsa']).agg({\n",
    "        'Pseudo-ID': 'count',\n",
    "        'Adjusted Basic Pay': 'mean',\n",
    "        'opm_occ_code': 'first',\n",
    "        'opm_occ_title': 'first',\n",
    "        'census_occ_code': 'first',\n",
    "        'census_occ_title': 'first',\n",
    "        'county': 'first',\n",
    "        'state': 'first',\n",
    "    })\n",
    "\n",
    "    # Cleap up collapsed df and export\n",
    "    collapsed_df.reset_index(inplace = True)\n",
    "    collapsed_df.rename(columns = {'Pseudo-ID': 'opm_n_emp', 'Adjusted Basic Pay': 'mean_abp'}, inplace = True)\n",
    "    \n",
    "    target_path = Path(binary_path).joinpath(f'opm_collapsed_{year}.feather')\n",
    "    collapsed_df.to_feather(target_path)\n",
    "\n",
    "    opm_collapsed_feather_path_dict[year] = str(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionaries for paths of binaries\n",
    "with open('../code_output/opm_collapsed_pre2014_feather_path_dict.json', 'w') as outfile:\n",
    "    json.dump(opm_collapsed_feather_path_dict, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d17b7b52486b7ddd73814d01c6691018dc71175d95eb65a2b9cd66e1b85695ed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
